## SPARK ON YARN环境配置

在yarn-site.xml中添加如下配置

```xml
# 修改
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>spark_shuffle,mapreduce_shuffle</value>
</property>
# 添加
<property>
    <name>yarn.nodemanager.aux-services.spark_shuffle.class</name>
    <value>org.apache.spark.network.yarn.YarnShuffleService</value>
</property>
<!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --><property>
     <name>yarn.nodemanager.pmem-check-enabled</name>
     <value>false</value>
</property>
<!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true -->
<property>
      <name>yarn.nodemanager.vmem-check-enabled</name>
      <value>false</value>
</property>
```

检查一下**${HADOOP_HOME}/share/hadoop/yarn/lib**目录下是否有spark-*-yarn-shuffle.jar，其中*代表spark版本号，如果没有需要从spark的安装目录下拷贝过来。

**spark-\*-yarn-shuffle.jar在spark的yarn目录下**

修改spark-env.sh，添加如下配置：

vim spark-env.sh

```shell
YARN_CONF_DIR=/home/workspace/hadoop-2.10.1/etc/hadoop
```

测试代码：

```shell
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode client \
./examples/jars/spark-examples_2.12-3.1.1.jar \
100
```
