

















**前期准备**

```shell
# 创建数据目录，日志目录，pid目录
sudo mkdir -p /data/kafka-eagle-3.0.1/{db,logs}
sudo chown -R zhongtai:zhongtai /data/kafka-eagle-3.0.1
```

**下载解压**

```shell
tar -zxvf kafka-eagle-bin-3.0.1.tar.gz -C /opt/
tar -zxvf /opt/kafka-eagle-bin-3.0.1/efak-web-3.0.1-bin.tar.gz -C /opt/kafka-eagle-bin-3.0.1
rm /opt/kafka-eagle-bin-3.0.1/efak-web-3.0.1-bin.tar.gz
```

**配置环境变量**

```shell
> vim ~/.bashrc

# Kafka EFAK
export KE_HOME=/opt/kafka-eagle-bin-3.0.1/efak-web-3.0.1
export PATH=$PATH:$KE_HOME/bin

> source ~/.bashrc
```

**配置组件参数**

​		该组件参数在$KE_HOME/conf目录下的system-config.properties文件中。

```shell
# 配置ZK连接信息
efak.zk.cluster.alias=cluster1
# [注意] 该配置需要主要和kafka配置文件中的zookeeper.connect属性需要完全一致
cluster1.zk.list=hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181/kafka-2.1.1

# 配置WebUI端口
efak.webui.port=8048

# 配置kafka offset存储
# [注意] 如果kafka版本大于1.0则需要配置为kafka，则否配置为zk
cluster1.efak.offset.storage=kafka

# 配置元信息存储，这里配置为本地的sqlite数据库，当然也可以配置为mysql
######################################
# kafka sqlite jdbc driver address
######################################
efak.driver=org.sqlite.JDBC
efak.url=jdbc:sqlite:/data/kafka-eagle-3.0.1/db/ke.db
efak.username=root
efak.password=www.kafka-eagle.org

######################################
# kafka mysql jdbc driver address
######################################
#efak.driver=com.mysql.cj.jdbc.Driver
#efak.url=jdbc:mysql://127.0.0.1:3306/ke?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull
#efak.username=root
#efak.password=123456
```

​		在$KE_HOME/conf/works文件下配置当前节点域名或者IP。

**配置日志存储**

​		在$KE_HOME/bin/ke.sh配置如下参数：

```shell
# LOG_DIR=${KE_HOME}/logs
LOG_DIR=/data/kafka-eagle-3.0.1/logs
```

​		在$KE_HOME/conf/log4j.properties 更改如下参数：

```shell
#log4j.appender.SLOG.File=logs/log.log
log4j.appender.SLOG.File=/data/kafka-eagle-3.0.1/logs/log.log

#log4j.appender.SERROR.File=logs/error.log
log4j.appender.SERROR.File=/data/kafka-eagle-3.0.1/logs/error.log
```

**启动服务**

```shell
chmod u+x $KE_HOME/bin/ke.sh
$KE_HOME/bin/ke.sh start
```

​		启动成功后访问WebUI，'http://<ip>:8048，用户名和密码默认分别为admin和123456。



# FAQ

（1）无法获取Kafka元数据信息。

​		需要检查system-config.properties文件中的cluster1.zk.list属性必须和Kafka配置文件中的zookeeper.connect属性需要完全一致。

（2）获取kafka元数据信息后无法找到合适端口。

​		堆栈异常如下：

```shell
[2023-02-20 10:38:43] KafkaCacheUtils.Thread-6 - ERROR - Telnet [hcdb-data5:-1] has error, msg is
 java.lang.IllegalArgumentException: port out of range:-1
        at java.net.InetSocketAddress.checkPort(InetSocketAddress.java:143)
        at java.net.InetSocketAddress.<init>(InetSocketAddress.java:224)
        at org.smartloli.kafka.eagle.common.util.NetUtils.telnet(NetUtils.java:45)
        at org.smartloli.kafka.eagle.common.util.KafkaCacheUtils.refreshKafkaMetaData(KafkaCacheUtils.java:150)
        at org.smartloli.kafka.eagle.common.util.KafkaCacheUtils.initKafkaMetaData(KafkaCacheUtils.java:65)
        at org.smartloli.kafka.eagle.web.controller.StartupListener$ContextSchema.initKafkaMetaData(StartupListener.java:74)
        at org.smartloli.kafka.eagle.web.controller.StartupListener$ContextSchema.run(StartupListener.java:70)
[2023-02-20 10:38:43] KafkaCacheUtils.Thread-6 - ERROR - Telnet [hcdb-data6:-1] has error, msg is
```

​		该异常可能是因为kafka代理节点没有开启JMX服务是的监控服务无法获取到信息。解决方式可以参考官网：[Kafka Enable JMX PORT](https://docs.kafka-eagle.org/6.faq/1.faq#6.1.2-kafka-enable-jmx-port)。

# 附录

​		（1）[官方网站](http://www.kafka-eagle.org/)

​		（2）[代码仓库](https://github.com/smartloli/EFAK)