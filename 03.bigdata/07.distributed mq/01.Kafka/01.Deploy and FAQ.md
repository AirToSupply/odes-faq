#                                     一.节点规划

| 外网IP       | 内网IP                      | Broker |
| ------------ | --------------------------- | ------ |
| 172.16.3.121 | 192.168.3.121（hcdb-data4） | √      |
| 172.16.3.124 | 192.168.3.124（hcdb-data5） | √      |
| 172.16.3.125 | 192.168.3.125（hcdb-data6） | √      |



# 二.安装部署

## 1.前置准备

​		创建相关路径。

```shell
mkdir -p /data/kafka-2.1.1/{kafka-logs,log}
```

​		解压安装包并配置环境变量

```shell
> tar -zxvf kafka_2.12-2.1.1.tgz -C /opt
> vim ~/.bashrc

export KAFKA_HOME=/opt/kafka_2.12-2.1.1
export PATH=$PATH:$KAFKA_HOME/bin

source ~/.bashrc
```



## 2.代理节点参数配置

​		进入kafka根目录下的conf文件夹，配置server.properties文件。

```shell
# 代理节点标识符
# [注意] 该参数每个kafka broker进程该配置不同，这代表着每个代理节点的唯一标识，而且必须是全局唯一，只能是数字
broker.id=0

# 监听IP和端口配置
# [注意] 每个kafka broker进程配置不同，普通配置如下：
# listeners=PLAINTEXT://172.16.3.121:9092
# 如果需要配置内外网卡分流，可以配置如下：
# 定义Kafka Broker的Listener的配置项
listeners=INTERNAL://hcdb-data4:9092,EXTERNAL://172.16.3.121:19092
# 将Broker的Listener信息发布到Zookeeper中
advertised.listeners=INTERNAL://hcdb-data4:9092,EXTERNAL://172.16.3.121:19092
# 配置监听者的安全协议
listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
# 用于指定Kafka集群中Broker之间的通信
inter.broker.listener.name=INTERNAL

# 数据传输线程数，建议配置总核心数的50%中的2/3
num.network.threads=9
# 写磁盘线程数，建议配置总核心数的50%
num.io.threads=16
# 副本拉取线程数，建议配置总核心数的50%的1/3
num.replica.fetchers=4

socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600

# 数据存放的目录，多个目录用逗号分隔
log.dirs=/data/kafka-2.1.1/kafka-logs

# 主题
# 默认主题分区个数
num.partitions=1
# 单条消息最大长度，这里配置为5MB
message.max.bytes=5242880
# 可复制的消息的最大字节数，这里配置为5.5MB
replica.fetch.max.bytes=5767168
# 关闭自动创建主题
auto.create.topics.enable=false
# 允许删除主题
delete.topic.enable=true

# zk连接配置
# [注意] 这里建议添加上注册到zk的node名称，否则为会散乱的存储在zk的跟节点上，不以利后期维护管理
zookeeper.connect=hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181/kafka-2.1.1
zookeeper.connection.timeout.ms=6000
```

##   3.JVM优化

​			关于kafka服务进程JVM参数配置主要是在$KAFKA_HOME/bin/kafka-server-start.sh脚本中，这里推荐采用G1垃圾收集器。配置如下：

```shell
...

if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx6g -Xms6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:+ExplicitGCInvokesConcurrent"
fi

...
```

## 4.日志存储

​		日志存储路径主要在$KAFKA_HOME/bin/kafka-run-class.sh脚本中，配置如下：

```shell
...

# Log directory to use
LOG_DIR=/data/kafka-2.1.1/log
if [ "x$LOG_DIR" = "x" ]; then
  LOG_DIR="$base_dir/logs"
fi

...
```

##   5.扩展脚本

​		开发扩展kafka启停脚本，可以使其在一台节点跨节点启动kafka集群。主要步骤如下：

​		编写代理节点配置清单。

```shell
> vim $KAFKA_HOME/config/.brokers

hcdb-data4
hcdb-data5
hcdb-data6
```

​		在$KAFKA_HOME/bin目录下编写自治扩展脚本broker-daemon.sh：

```shell
#!/bin/bash

function check_process()
{
  pid=$(ps -ef 2>/dev/null | grep -i "kafka.Kafka" | grep -v grep | awk '{print $2}')
  echo $pid
  [ "$pid" ] && return 0 || return 1
}

function broker_start()
{
  metapid=$(check_process)
  if [ -n "$metapid" ]; then
    echo "Kafka Broker [pid: $metapid] has already exists!"
    return
  fi

  cmd="$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties"
  
  eval $cmd

  if [ $? -eq 0 ]; then
    echo "Kafka Broker has been running!"
  else
    echo "Kafka Broker has been failed!"
  fi
}

function broker_stop()
{
  metapid=$(check_process)
  [ "$metapid" ] && $KAFKA_HOME/bin/kafka-server-stop.sh || echo "Kafka Broker has been not running!"
}

case $1 in

"start")
  broker_start
  ;;

"stop")
  broker_stop
  ;;

"restart")
  broker_stop
  sleep 2
  broker_start
  ;;

"status")
  check_process >/dev/null && echo "Kafka Broker [Active]" || echo "Kafka Broker [Inactive]"
  ;;

*)
  echo Invalid Args!
  echo 'Usage: '$(basename $0)' start|stop|restart|status'
  ;;

esac
```

​		在$KAFKA_HOME/bin目录下编写统筹脚本kafka-server.sh：

```shell
#!/bin/bash

for node in `cat $KAFKA_HOME/config/.brokers`
do
  echo "********************************" [ $node ] "************************************"
  ssh $node $KAFKA_HOME/bin/broker-daemon.sh $1
  echo "*******************************************************************************"
done
```

​		完成上述所有步骤之后需要将kafka目录分发到对应的服务器节点，然后只需要在其中一台执行如下指令即启动集群。

```shell
$KAFKA_HOME/bin/kafka-server.sh start
```

   

# 运维管理

## 创建主题

​		例如创建一个名称为t1的主题，同时指定1个分区和1个副本。

```shell
$KAFKA_HOME/bin/kafka-topics.sh --create \
--zookeeper hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181/kafka-2.1.1 \
--replication-factor 1 \
--partitions 1 \
--topic t1
```

​		【注意】这里的--zookeeper必须对应$KAFKA_HOME/config/server.properties配置文件中的zookeeper.connect参数所对应的值，容易出错的地方在于如果配置了kafka注册到节点znode，那么在通过kafka-topics.sh操作主题时--zookeeper参数也必须附带上这个znode，否则会有如下异常：

```shell
ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 1 larger than available brokers: 0.
 (kafka.admin.TopicCommand$)
```

## 查看主题

【查看单个主题】

```shell
$KAFKA_HOME/bin/kafka-topics.sh --describe \
--zookeeper hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181/kafka-2.1.1 \
--topic t1
```

```shell
Topic:t1        PartitionCount:1        ReplicationFactor:1     Configs:
        Topic: t1       Partition: 0    Leader: 2       Replicas: 2     Isr: 2
```

【列出所有主题】

```shell
$KAFKA_HOME/bin/kafka-topics.sh --list \
--zookeeper hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181/kafka-2.1.1
```

```shell
t1
```

## 删除主题

【方式一】

```shell
$KAFKA_HOME/bin/kafka-run-class.sh kafka.admin.TopicCommand --delete \
--zookeeper hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181/kafka-2.1.1 \
--topic t1
```

```shell
Topic t1 is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
```

【方式二】

```shell
$KAFKA_HOME/bin/kafka-topics.sh --delete \
--zookeeper hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181/kafka-2.1.1 \
--topic t1
```

## 主题位移

```shell
# 查看主题位移
$KAFKA_HOME/bin/kafka-run-class.sh kafka.tools.GetOffsetShell \
--broker-list hcdb-data4:9092,hcdb-data5:9092,hcdb-data6:9092 \
--topic t1

# 获取主题最近位移
$KAFKA_HOME/bin/kafka-run-class.sh kafka.tools.GetOffsetShell \
--broker-list hcdb-data4:9092,hcdb-data5:9092,hcdb-data6:9092 \
--topic t1 \
--time -1

# 获取主题最早位移
$KAFKA_HOME/bin/kafka-run-class.sh kafka.tools.GetOffsetShell \
--broker-list hcdb-data4:9092,hcdb-data5:9092,hcdb-data6:9092 \
--topic t1 \
--time -2
```



## 生产消息

【使用内部网卡】

```shell
$KAFKA_HOME/bin/kafka-console-producer.sh \
--broker-list hcdb-data4:9092,hcdb-data5:9092,hcdb-data6:9092 \
--topic t1
```

【使用外部网卡】

```shell
$KAFKA_HOME/bin/kafka-console-producer.sh \
--broker-list 172.16.3.121:19092,172.16.3.124:19092,172.16.3.125:19092 \
--topic t1
```

## 消费消息

【使用内部网卡】

```shell
$KAFKA_HOME/bin/kafka-console-consumer.sh \
--bootstrap-server hcdb-data4:9092,hcdb-data5:9092,hcdb-data6:9092 \
--topic t1 \
--from-beginning
```

【使用外部网卡】

```shell
$KAFKA_HOME/bin/kafka-console-consumer.sh \
--bootstrap-server 172.16.3.121:19092,172.16.3.124:19092,172.16.3.125:19092 \
--topic t1 \
--from-beginning
```

## 查看消费者组

```shell
$KAFKA_HOME/bin/kafka-consumer-groups.sh \
--bootstrap-server hcdb-data4:9092,hcdb-data5:9092,hcdb-data6:9092 \
--list
```

## 查看消费者组详细消费情况

```shell
$KAFKA_HOME/bin/kafka-consumer-groups.sh \
--bootstrap-server hcdb-data4:9092,hcdb-data5:9092,hcdb-data6:9092 \
--group console-consumer-51788 \
--describe
```



# FAQ

（1）Kafka的重要参数有哪些？

​		①acks
​           acks = 0 ：不接收发送结果
​           acks = all 或者 -1:：表示发送消息时，不仅要写入本地日志，还要等待所有副本写入成功。
​           acks = 1:：写入本地日志即可，是上述二者的折衷方案，也是默认值。

​        ②retries

​          默认为 0，表示：不重试，立即失败。

​          大于 0 表示：重试次数。

​         ③buffer.memory

​         指定 producer 端用于缓存消息的缓冲区的大小，默认 32M；适当提升该参数值，可以增加一定的吞吐量。  

​         ④batch.size

​			producer 会将发送分区的多条数据封装在一个 batch 中进行发送，这里的参数指的就是 batch 的大小。该参数值过小的话，会降低吞吐量，过大的话，会带来较大的内存压力。默认为 16K，建议合理增加该值。

  （2）丢失数据的场景有哪些？

​           consumer 端：不是严格意义的丢失，其实只是漏消费了。设置了 `auto.commit.enable=true` ，当 consumer fetch 了一些数据但还没有完全处理掉的时候，刚好到 commit interval 触发了提交 offset 操作，接着 consumer 挂掉。这时已经fetch的数据还没有处理完成但已经被commit掉，因此没有机会再次被处理，数据丢失。

​            producer 端：I/O 线程发送消息之前，producer 崩溃， 则 producer 的内存缓冲区的数据将丢失。

   （3）如何在Spring Boot服务中通过Java代码优雅的删除主题。

​             这里介绍一种异步删除的方式，采用KafkaAdminClient API。骨架代码如下：

```java
AdminClient adminClient = null;
try {
    Properties properties = new Properties();
    // kafkaServerUrl = bigdata06:9092
    properties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, kafkaServerUrl);
    adminClient = KafkaAdminClient.create(properties);
    DeleteTopicsResult deleteTopicsResult = adminClient.deleteTopics(topics);
    Map<String, KafkaFuture<Void>> deleteStates = deleteTopicsResult.values();
    for (Map.Entry<String, KafkaFuture<Void>> deleteState : deleteStates.entrySet()) {
        String topic = deleteState.getKey();
        try {
            deleteState.getValue().get();
            log.info("Topic: {} is deleted", topic);
        } catch (ExecutionException e) {
            if (e.getCause() instanceof UnknownTopicOrPartitionException) {
                log.error("Topic: {} is not existed in kafka broker", topic);
            } else {
                e.printStackTrace();
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
} catch (Exception e) {
    e.printStackTrace();
} finally {
    if (Objects.nonNull(adminClient)) {
        adminClient.close();
    }
}
```

​      关于kafka更多问题可以参考：https://zhuanlan.zhihu.com/p/65512721。

  （4）kafka单条消息过大产生MessageSizeTooLargeException异常。

​		假设需要单条容量为5MB，需要注意如下三个因素：

​		①生产者，可配置$KAFKA_HOME/config/producer.properties。

```shell
# 请求的最大大小为字节，这里配置为5MB
max.request.size=5242880
```

​		【注意】该参数不能超过message.max.bytes。

​		②服务端，可配置$KAFKA_HOME/config/server.properties。

```shell
# 单条消息最大长度，这里配置为5MB
message.max.bytes=5242880
# 可复制的消息的最大字节数，这里配置为5.5MB
replica.fetch.max.bytes=5767168
```

​		【注意】message.max.bytes不能超过replica.fetch.max.bytes。

​		③消费者，可配置$KAFKA_HOME/config/consumer.properties。

```shell
# 消费者能读取的最大消息，默认50MB
# fetch.message.max.bytes=
```

​		【注意】fetch.message.max.bytes需要大于等于message.max.bytes。



# 参考文献

​	（1）[kafka的安装部署](https://blog.51cto.com/flyfish225/5919685)

​	（2）[Kafka性能优化](https://cloud.tencent.com/developer/article/2184950)

​	（3）[Kafka之常用参数配置整理](https://blog.csdn.net/weixin_44692700/article/details/126360894)

​	（4）[Kafka JVM参数配置优化](https://blog.csdn.net/weixin_39700625/article/details/114756524?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-114756524-blog-124288759.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-114756524-blog-124288759.pc_relevant_default&utm_relevant_index=2)
