## 一.节点规划

|                           | Master | Worker |
| ------------------------- | ------ | ------ |
| 10.232.3.217（bigdata01） | √      | √      |
| 10.232.3.218（bigdata02） | √      |        |
| 10.232.3.220（bigdata04） |        | √      |
| 10.232.3.221（bigdata05） |        | √      |



## 二.安装步骤

​		（1）解压安装包

```shell
tar zxvf /tmp/modules/spark-3.1.1-bin-hadoop2.7.tgz -C .
cd /workspace/opt/spark-3.1.1-bin-hadoop2.7
```

​		（2）配置相关文件

​		【spark-defaults.conf】

```shell
spark.master.rest.enabled        true
spark.master.rest.port           16066
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs://ns/spark_3.1.1/history
spark.history.fs.logDirectory    hdfs://ns/spark_3.1.1/history
spark.eventLog.compress         true
spark.history.ui.port           18888
spark.shuffle.service.enabled   true
spark.shuffle.service.port      7337
```

​		【spark-env.sh】

```shell
export JAVA_HOME=/workspace/opt/jdk1.8.0_201
export HADOOP_HOME=/workspace/opt/hadoop-2.10.1
export HADOOP_CONF_DIR=/workspace/opt/hadoop-2.10.1/etc/hadoop

# 注意：在目前分布在bigdata01和bigdata02上，他们的SPARK_MASTER_HOST配置不同
export SPARK_MASTER_HOST=bigdata02
export SPARK_MASTER_PORT=7077

# HA模式下配置
export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=bigdata01:2181,bigdata07:2181,bigdata04:2181 -Dspark.deploy.zookeeper.dir=/spark-3.1.1"

# worker进程工作目录
export SPARK_WORKER_DIR=/data1/spark-3.1.1/work
# 配置自动自动清理，清理周期以及保留最近多长时间的数据
export SPARK_WORKER_OPTS="-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.interval=86400 -Dspark.worker.cleanup.appDataTtl=2592000"

export SPARK_MASTER_WEBUI_PORT=18080
export SPARK_HISTORY_OPTS="-Dspark.history.ui.port=18888 -Dspark.history.retainedApplications=30 -Dspark.history.fs.logDirectory=hdfs://ns/spark_3.1.1/history"

# job任务在运行过程中产生大量的临时目录位置
export SPARK_LOCAL_DIRS=/data1/spark-3.1.1/tmp

# 配置ssh端口
export SPARK_SSH_OPTS="-p 43215"
```

​		【workers】

```shell
bigdata01
bigdata04
bigdata05
```

​	   （3）将Spark跟目录分发至对应的节点。

​       （4）启动服务。

​         ①在bigdata02上执行如下命令，启动所有服务。

```shell
${SPARK_HOME}/sbin/start-all.sh
```

​		 ②在bigdata01上执行如下命令，启动备用Master。

```shell
${SPARK_HOME}/sbin/start-master.sh
```

​		 ③测试与验证，这里执行一个Spark官方自带的批任务。

```shell
${SPARK_HOME}/bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://bigdata01:7077,bigdata02:7077 \
${SPARK_HOME}/examples/jars/spark-examples_2.12-3.1.1.jar 10
```

​		输出如下内容，证明Spark集群正常。

```shell
Pi is roughly 3.141715141715142
```



## 三.FAQ

（1）通过spark-shell方式读取HDFS数据异常。

​         首先检查是否在环境变量以及${SPARK_HOME}/conf/spark-env.sh文件中配置HADOOP_HOME以及HADOOP_CONF_DIR这两个环境。如果仍然报错，需要将${HADOOP_HOME}/etc/hadoop目录下的core-site.xml以及hdfs-site.xml文件拷贝到${SPARK_HOME}/conf目录下，并且重启Spark集群。

（2）通过spark-shell方式探查hive表异常。

​         将${HIVE_HOME}/conf/目录下的hive-site.xml拷贝到${SPARK_HOME}/conf目录下，并且重启Spark集群。如果仍然报错需要在spark-shell附加如下参数：

```shell
--driver-class-path /workspace/opt/apache-hive-2.3.8-bin/conf/
```

（3）如何通过spark集成hive（Spark on Hive）？

​		需要将hadoop的core-site.xml和hdfs-site.xml以及hive的hive-site.xml三个配置文件拷贝到spark的conf目录下，命令如下：

```shell
cp $HADOOP_HOME/etc/hadoop/core-site.xml $SPARK_HOME/conf
cp $HADOOP_HOME/etc/hadoop/hdfs-site.xml $SPARK_HOME/conf
cp $HIVE_HOME/conf/hive-site.xml $SPARK_HOME/conf
```

​		通过spark-sql进行查询验证，命令如下：

```shell
$SPARK_HOME/bin/spark-sql --master yarn --deploy-mode client --name spark-sql
```

​		运行结果如下：

```shell
spark-sql (default)> show databases;
namespace
default
ds
Time taken: 2.383 seconds, Fetched 2 row(s)
spark-sql (default)> use ds;
Response code
Time taken: 0.058 seconds
spark-sql (default)> show tables;
database        tableName       isTemporary
ds              ds_hive         false
Time taken: 0.093 seconds, Fetched 1 row(s)
spark-sql (default)> select * from ds_hive;
id      name
4       ww
1       zs
2       ls
3       mm
Time taken: 3.614 seconds, Fetched 4 row(s)
spark-sql (default)> select count(1) from ds_hive;
count(1)
4
Time taken: 0.819 seconds, Fetched 1 row(s)
```


