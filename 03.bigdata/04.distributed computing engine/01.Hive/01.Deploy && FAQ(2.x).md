## 一.节点规划

|                            | HiveMetaStore | HiveServer2 |
| -------------------------- | ------------- | ----------- |
| 10.232.3.217 （bigdata01） |               | √           |
| 10.232.3.218 （bigdata02） | √             |             |



## 二.安装步骤

（1）解压安装包。

```shell
tar zxvf apache-hive-2.3.8-bin.tar.gz -C /workspace/opt/
cd /workspace/opt/apache-hive-2.3.8-bin
```

（2）配置环境变量。

```shell
vim ~/.bashrc
```

​		配置如下环境变量：

```shell
export HIVE_HOME=/workspace/opt/apache-hive-2.3.8-bin
export PATH=$PATH:$HIVE_HOME/bin
```

​		生效环境变量：

```shell
source ~/.bashrc
```

  （3）在${HIVE_HOME}/conf目录下配置hive-site.xml文件，配置内容如下：

```xml
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://10.232.3.218:5432/hive?createDatabaseIfNotExist=true</value>
        <description>JDBC connect string for a JDBC metastore</description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
        <description>Driver class name for a JDBC metastore</description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>postgres</value>
        <description>username to use against metastore database</description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>postgres</value>
        <description>password to use against metastore database</description>
    </property>
    <property>
        <name>hive.cli.print.current.db</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.cli.print.header</name>
        <value>true</value>
    </property>
    
    <property>
        <name>hive.server2.thrift.port</name>
        <value>10000</value>
    </property>
    <property>
        <name>hive.server2.thrift.bind.host</name>
        <value>10.232.3.217</value>
    </property>
    <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
    </property>
    
    <property>
  		<name>hive.metastore.local</name>
  		<value>false</value>
    </property>
    <property>
  		<name>hive.aux.jars.path</name>
 		 <value>file:///workspace/opt/apache-hive-2.3.8-bin/lib/hudi-hadoop-mr-bundle-0.8.1-SNAPSHOT.jar</value>
	</property>

    <property>
	  <name>hive.metastore.uris</name>
	  <value>thrift://10.232.3.218:9083</value>
	</property>
</configuration>
```

（4）如果需要集成Hudi数据湖，需要编译hudi-hadoop-mr-bundle-xxx-SNAPSHOT.jar文件放置到$HIVE_HOME/auxlib/目录下。

```shell
mkdir -p $HIVE_HOME/auxlib
cp hudi-hadoop-mr-bundle-0.8.1-SNAPSHOT.jar $HIVE_HOME/auxlib/
```

（5）将${HADOOP_HOME}/etc/hadoop下的core-site.xml和hdfs-site.xml拷贝到${HIVE_HOME}/conf目录下。

```shell
cp ${HADOOP_HOME}/etc/hadoop/core-site.xml ${HIVE_HOME}/conf/
cp ${HADOOP_HOME}/etc/hadoop/hdfs-site.xml ${HIVE_HOME}/conf/
```

（6）Hive元数据初始化，这一步必须要做。

```shell
schematool -initSchema -dbType postgres -verbose
```

（7）启动metastore服务。

```shell
nohup hive --service metastore>metastore.log 2>&1 &
```

（8）启动hiveserver2服务。

```shell
nohup hive --service hiveserver2>hiveserver2.log 2>&1 &
```

（9）启动上述两个服务之后，可以通过HIVE提供的beeline尝试进行连接。

```shell
> $HIVE_HOME/bin/beeline

Beeline version 2.3.8 by Apache Hive

beeline> !connect jdbc:hive2://172.16.2.123:10000

Connecting to jdbc:hive2://172.16.2.123:10000
Enter username for jdbc:hive2://172.16.2.123:10000: hive
Enter password for jdbc:hive2://172.16.2.123:10000: ****
Connected to: Apache Hive (version 2.3.8)
Driver: Hive JDBC (version 2.3.8)
Transaction isolation: TRANSACTION_REPEATABLE_READ

0: jdbc:hive2://172.16.2.123:10000> select version();

+--------------------------------------------------+
|                       _c0                        |
+--------------------------------------------------+
| 2.3.8 rf1e87137034e4ecbe39a859d4ef44319800016d7  |
+--------------------------------------------------+
```

​		【注意】在没有配置用户名和密码的情况下，推荐通过hive作为用户名去登录。

## 三.问题指南

（1）连接hive metastore 出现异常：MetaStoreClient lost connection. Attempting to reconnect. 

​         解决方案一：在hive-site.xml中加上 hive.metastore.event.db.notification.api.auth=false

​         解决方案二：在core-site.xml中加上 hadoop.proxyuser.hive.hosts=xxxx和 hadoop.proxyuser.hive.groups=*

（2）执行#hive命令进入Hive CLI时报如下错误：

```shell
Exception in thread "main" java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
        at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:444)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:672)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:616)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
```

​		因为没有正常启动Hive的Metastore Server服务进程。 启动Metastore Server服务进程即可解决。

（3）执行#hive命令进入Hive CLI时报如下错误：

```shell
Logging initialized using configuration in jar:file:/home/hadoop/app/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties
Exception in thread "main" java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:522)
at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:677)
at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1523)
at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:86)
at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)
at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)
at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)
at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)
... 8 more
Caused by: java.lang.reflect.InvocationTargetException
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)
... 14 more
Caused by: MetaException(message:Got exception: java.io.IOException No FileSystem for scheme: hfds)
at org.apache.hadoop.hive.metastore.MetaStoreUtils.logAndThrowMetaException(MetaStoreUtils.java:1213)
at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:106)
at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:140)
at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:146)
at org.apache.hadoop.hive.metastore.Warehouse.getWhRoot(Warehouse.java:159)
at org.apache.hadoop.hive.metastore.Warehouse.getDefaultDatabasePath(Warehouse.java:177)
at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB_core(HiveMetaStore.java:600)
at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:620)
at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)
at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:66)
at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)
at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:199)
at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:74)
... 19 more
```

​		原因是在hadoop目录下存在老版本jline，将hadoop中share/hadoop/yarn/lib路径下jline包换成hive中匹配的jar包。

（4）Hive如何通过让当前任务进行死循环？

​		首先在线上生产环境不建议使用这种方式，但是在有些特殊情况下需要进行某种方式来模拟从而达到某种效果。会有如下方式：

​		**方式一**：自己编写自定义UDF，在函数逻辑中调用Thread.sleep方法。

​		**方式二**：通过Hive提供的内置UDF来间接调用。方式如下：

```sql
SELECT reflect("java.util.concurrent.locks.LockSupport", "park");
```

​		这种方式是通过反射来调用Java内库的API，需要注意的是只能调用类的静态方法。

（5）Hive如何统计数据表的指标。

```sql
-- 统计表指标
-- 注意：重点关注numFiles/numRows/rawDataSize/totalSize
ANALYZE TABLE <tb> COMPUTE STATISTICS;
-- 统计列指标
-- 注意：重点关注COLUMN_STATS_ACCURATE
ANALYZE TABLE <tb> COMPUTE STATISTICS FOR COLUMNS <col, ...>;
-- 查看指标
DESC FORMATTED <tb>;
```

​		例子如下：

```shell
> create table hive_meta_collect(id int, name string);
> insert into hive_meta_collect values(1, "1"), (2, "2");
> ANALYZE TABLE hive_meta_collect COMPUTE STATISTICS;
> DESC FORMATTED hive_meta_collect;

col_name        data_type       comment
# col_name              data_type               comment

id                      int
name                    string

# Detailed Table Information
Database:               default
Owner:                  zhongtai
CreateTime:             Wed Dec 14 14:13:52 CST 2022
LastAccessTime:         UNKNOWN
Retention:              0
Location:               hdfs://ns/user/hive/warehouse/hive_meta_collect
Table Type:             MANAGED_TABLE
Table Parameters:
        COLUMN_STATS_ACCURATE   {\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"id\":\"true\",\"name\":\"true\"}}
        numFiles                1
        numRows                 2
        rawDataSize             6
        totalSize               8
        transient_lastDdlTime   1670998572

# Storage Information
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
InputFormat:            org.apache.hadoop.mapred.TextInputFormat
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
Compressed:             No
Num Buckets:            -1
Bucket Columns:         []
Sort Columns:           []
Storage Desc Params:
        serialization.format    1
```

​		关于Hive表指标统计可以参考：[通过hive元数据查询hive库和表的总条数](https://blog.csdn.net/love910809/article/details/121948784)