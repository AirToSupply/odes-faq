## 节点规划

|                           | HiveMetaStore | HiveServer2 |
| ------------------------- | ------------- | ----------- |
| 172.16.3.111 （hcdb-nn1） | √             |             |
| 172.16.3.122 （hcdb-nn2） | √             | √           |



## 前置准备

​		（1）解压安装包

```shell
tar -zxvf apache-hive-3.1.2-bin.tar.gz -C /opt
```

​		（2）配置环境变量

```shell
> vim ~/.bashrc

export HIVE_HOME=/opt/apache-hive-3.1.2-bin
export PATH=$PATH:$HIVE_HOME/bin

> source ~/.bashrc
```

​		（3）创建Hive MetaStore元数据库以及相关授权

```sql
CREATE USER hive WITH PASSWORD '%hive@hcdb%';
CREATE DATABASE hive WITH OWNER = hive;
GRANT ALL PRIVILEGES ON DATABASE hive TO hive;
```

​		（4）Hive MetaStore元数据库密码隐藏配置

​		hive-site.xml配置文件中javax.jdo.option.ConnectionPassword参数需要明文配置Hive MetaStore元数据库密码，这非常不安全，所以这里可以使用Hadoop JCEK来生成秘文。

```shell
hadoop credential create javax.jdo.option.ConnectionPassword -provider jceks://file/$HIVE_HOME/conf/hive-metastore-password.jceks
```

​		（5）数据库驱动

```shell
cp postgresql-42.2.8.jar $HIVE_HOME/lib
```



## 初始化数据库

​		在$HIVE_HOME/conf目录下创建hive-site.xml配置文件，并配置元数据库连接信息。

```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 数据库连接 -->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://hcdb-nn1:5432/hive?createDatabaseIfNotExist=true</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <!--
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value></value>
    </property>
    -->
    <property>
        <name>hadoop.security.credential.provider.path</name>
        <value>jceks://file//opt/apache-hive-3.1.2-bin/conf/hive-metastore-password.jceks</value>
    </property>
    <!-- 数据库连接 -->
    
    <!-- Hive默认在HDFS的工作目录 -->
    <property>
      <name>hive.metastore.warehouse.dir</name>
      <value>/user/hive/warehouse</value>
    </property>

</configuration>
```

​		配置完成后进行元数据初始化。

```shell
$HIVE_HOME/bin/schematool -initSchema -dbType postgres -verbose
```



## 基础项配置

​		所有关于hive的配置项目均需要配置在$HIVE_HOME/conf目录下创建hive-site.xml配置文件中。

### 命令行终端配置

​		如下配置主要是为了在使用hive cli命令行终端获取显示结果有更好的体验。

```xml
<!-- hive cli配置 -->
<property>
    <name>hive.cli.print.current.db</name>
    <value>true</value>
</property>
<property>
    <name>hive.cli.print.header</name>
    <value>true</value>
</property>
<!-- hive cli配置 -->
```

### metastore服务配置

```xml
<!-- hive metastore服务配置 -->
<property>
    <name>hive.metastore.uris</name>
    <value>thrift://hcdb-nn1:9083</value>
</property>
<property>
    <name>hive.metastore.local</name>
    <value>false</value>
</property>
<property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
</property>
<!-- 开启metastore服务metrics -->
<property>
  <name>hive.metastore.metrics.enabled</name>
  <value>true</value>
</property>
<!-- 元数据连接超时 默认:600s-->
<property>
  <name>hive.metastore.client.socket.timeout</name>
  <value>1200s</value>
</property>
<property>
    <name>hive.metastore.event.db.notification.api.auth</name>
    <value>false</value>
</property>
<!-- hive metastore服务配置 -->
```

【注意】参数**hive.metastore.client.socket.timeout**可以适当调大，来减少类似Read timed out 的SocketTimeoutException异常。

### metastore服务配置（HA）

​		hive.metastore.uris可以配置该服务在多个服务器上来达到高可用。在非高可用的配置模式下需要增加如下配置：

```xml
<property>
    <name>hive.metastore.uris</name>
	<value>thrift://hcdb-nn1:9083,thrift://hcdb-nn2:9083</value>
</property>
<property>
    <name>hive.cluster.delegation.token.store.class</name>
    <value>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore</value>
</property>
<property>
    <name>hive.cluster.delegation.token.store.zookeeper.connectString</name>
    <value>hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181</value>
</property>
<property>
    <name>hive.cluster.delegation.token.store.zookeeper.znode</name>
    <value>/hive-3.1.2/delegation</value>
</property>
```

【注意】

​		（1）参数hive.cluster.delegation.token.store.class：代理token的存储实现类，默认是存储在内存中，实现类为org.apache.hadoop.hive.thrift.MemoryTokenStore。生产环境下推荐配置为ZK可以达到负载均衡的效果。

​		（2）参数hive.cluster.delegation.token.store.zookeeper.connectString：zk的token存储连接串，默认是localhost:2181。

​		（3）参数hive.cluster.delegation.token.store.zookeeper.znode：表示token存储的节点跟路径，默认是/hivedelegation。

### hiveserver2服务配置

```xml
<!-- hiveserver2服务配置 -->
<property>
    <name>hive.server2.thrift.port</name>
    <value>10000</value>
</property>
<property>
    <name>hive.server2.thrift.bind.host</name>
    <value>172.16.3.122</value>
</property>
<!-- 配置thrift服务的验证账户和密码 -->
<property>
    <name>hive.server2.thrift.client.user</name>
    <value>hive</value>
</property>
<property>
    <name>hive.server2.thrift.client.password</name>
    <value>hive</value>
</property>
<property>
    <name>hive.server2.metrics.enabled</name>
    <value>true</value>
</property>
<property>
    <name>hive.server2.enable.doAs</name>
    <value>true</value>
</property>
<property>
    <name>hive.server.tcp.keepalive</name>
    <value>false</value>
</property>
<!-- 读取数据超时时间 -->
<property>
    <name>hive.server.read.socket.timeout</name>
    <value>1800s</value>
</property>
<property>
    <name>hive.server2.thrift.login.timeout</name>
    <value>120s</value>
</property>
<!-- 会话将在这段时间内未访问时关闭 -->
<property>
    <name>hive.server2.idle.session.timeout</name>
    <value>2h</value>
</property>
<!-- 当在此时间段内未访问时，操作将关闭 -->
<property>
    <name>hive.server2.idle.operation.timeout</name>
    <value>1h</value>
</property>
<!-- 会话操作超时的检查间隔 -->
<property>
    <name>hive.server2.session.check.interval</name>
    <value>1800s</value>
</property>
<!-- 规避hiveserver启动以为tez引擎缺失导致慢启动 -->
<property>
    <name>hive.server2.active.passive.ha.enable</name>
    <value>true</value>
</property>
<!-- hiveserver2服务配置 -->
```

【注意】

​		①参数**hive.server2.enable.doAs**的设置对于通过beeline连接hive非常重要，生产环境建议开启该参数。开启该功能表示hive保证各用户之间操作是隔离。如果没有开启，无论通过任何用户通过登录beeline访问hive所采用的操作用户是启动HiveServer2该进程的用户，这不利于后期权限认证的集成。

​		②关于会话超时设置的规则是：hive.server2.session.check.interval < hive.server2.idle.operation.timeout < hive.server2.idle.session.timeout。

​		③这种方式配置之后，连接方式如下：

```shell
$HIVE_HOME/bin/beeline -u "jdbc:hive2://172.16.3.122:10000/default" -n hive -p hive
```

​		其中IP和port分别是参数hive.server2.thrift.bind.host和参数hive.server2.thrift.port所指定的。

### hiveserver2服务配置（HA）

​		关于该HA的其他方案可以参考：[HiveServer2的负载均衡高可用与ActicePassive高可用浅析](https://www.jianshu.com/p/f9b14299ca9a)。

​		在非高可用模式配置的基础上，替换成如下配置：

```xml
<property>
    <name>hive.server2.thrift.port</name>
    <value>10000</value>
</property>
<property>
    <name>hive.server2.thrift.bind.host</name>
    <value>0.0.0.0</value>
</property>
<property>
	<name>hive.server2.support.dynamic.service.discovery</name>
	<value>true</value>
</property>
<property>
	<name>hive.server2.zookeeper.namespace</name>
	<value>/hive-3.1.2/hiveserver2</value>
</property0>
<property>
	<name>hive.zookeeper.quorum</name>
	<value>hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181</value>
</property>
<property>
	<name>hive.zookeeper.client.port</name>
	<value>2181</value>
</property>
```

【注意】该服务采用HA模式，通过beeline的连接则有对应变化。

```shell
jdbc:hive2://hcdb-data2:2181,hcdb-data3:2181,hcdb-data4:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=/hive-3.1.2/hiveserver2
```



### 引擎内核优化

#### 动态分区

```xml
<!-- 动态分区设置 -->
<property>
    <name>hive.exec.dynamic.partition</name>
    <value>true</value>
</property>
<property>
    <name>hive.exec.max.dynamic.partitions</name>
    <value>10000</value>
</property>
<property>
    <name>hive.exec.max.dynamic.partitions.pernode</name>
    <value>10000</value>
</property>
<property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>nonstrict</value>
</property>
<!-- 动态分区设置 -->
```

#### 任务并行化

```xml
<!-- 任务并行化 -->
<property>
    <name>hive.exec.parallel</name>
    <value>true</value>
</property>
<!-- 任务并行化 -->
```

#### 本地化配置

```xml
<!-- 本地化配置 -->
<property>
    <name>hive.exec.mode.local.auto</name>
    <value>true</value>
</property>
<!-- 本地化配置 -->
```

​		本地化执行必须满足如下条件：

​	（1）job的输入数据大小必须小于参数hive.exec.mode.local.auto.inputbytes.max（默认128MB）。
​	（2）job的map数必须小于参数hive.exec.mode.local.auto.tasks.max（默认为4）太多没有足够的slots。
​	（3）job的reduce数必须为0或1。

#### 小文件配置

​		输入端

```xml
<!-- 小文件配置 -->
<property>
    <name>hive.input.format</name>
    <value>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</value>
</property>
```

​		输出端

```xml
<property>
    <name>hive.merge.mapfiles</name>
    <value>true</value>
</property>
<property>
    <name>hive.merge.mapredfiles</name>
    <value>true</value>
</property>
<property>
    <name>hive.merge.smallfiles.avgsize</name>
    <value>256000000</value>
</property>
<property>
    <name>hive.merge.orcfile.stripe.level</name>
    <value>false</value>
</property>
<!-- 小文件配置 -->
```

【注意】参数hive.merge.orcfile.stripe.level设置为true表示orc文件进行stripe Level级别的合并，当设置为false,orc文件进行文件级别的合并。

#### 压缩配置

```xml
<!-- 压缩配置 -->
<property>
    <name>hive.exec.compress.output</name>
    <value>true</value>
</property>
<property>
    <name>hive.exec.compress.intermediate</name>
    <value>true</value>
</property>
<property>
    <name>hive.intermediate.compression.codec</name>
    <value>org.apache.hadoop.io.compress.SnappyCodec</value>
</property>
<property>
    <name>hive.intermediate.compression.type</name>
    <value>BLOCK</value>
</property>
<property>
    <name>mapreduce.output.fileoutputformat.compress</name>
    <value>true</value>
</property>
<property>
    <name>mapreduce.output.fileoutputformat.compress.codec</name>
    <value>org.apache.hadoop.io.compress.SnappyCodec</value>
</property>
<property>
    <name>mapreduce.output.fileoutputformat.compress.type</name>
    <value>BLOCK</value>
</property>
<!-- 压缩配置 -->
```

【注意】

​		参数hive.exec.compress.output：开启表示map/reduce 输出压缩（一般采用序列化文件存储），最终输出用gzip好，减少储存空间。。

​		参数hive.exec.compress.intermediate：开启表示对任务中间数据压缩，中间压缩常用SnappyCodec ，这样CPU消耗较低。

​		参数compression.type：表示按块压缩，而不是记录压缩。

#### 数据倾斜

```xml
<!-- 数据倾斜 -->
<property>
    <name>hive.groupby.skewindata</name>
    <value>true</value>
</property>
<property>
    <name>hive.optimize.skewjoin</name>
    <value>true</value>
</property>
<property>
    <name>hive.optimize.skewjoin.compiletime</name>
    <value>true</value>
</property>
<property>
    <name>hive.optimize.union.remove</name>
    <value>true</value>
</property>
<!-- 数据倾斜 -->
```

#### CBO

```xml
<!-- CBO -->
<property>
    <name>hive.cbo.enable</name>
    <value>true</value>
</property>
<property>
    <name>hive.compute.query.using.stats</name>
    <value>true</value>
</property>
<property>
    <name>hive.stats.fetch.column.stats</name>
    <value>true</value>
</property>
<property>
    <name>hive.stats.fetch.partition.stats</name>
    <value>true</value>
</property>
<!-- CBO -->
```

#### 指标收集

```xml
<!-- 模式情况下在执行insert指令时，会自动收集一些列的信息 但同时在该版本会造成在beeline客户端模式下执行指令最终的返回堆栈异常，但是结果是执行成功的，建议关闭 -->
<property>
    <name>hive.stats.autogather</name>
    <value>false</value>
</property>
```



## JVM内存配置与优化

### metastore内存

```shell
> vim $HIVE_HOME/bin/ext/metastore.sh

export HIVE_METASTORE_HADOOP_OPTS="-Xms1024m -Xmx1024m"
```

### hiveserver2内存

```shell
> vim $HIVE_HOME/bin/ext/hiveserver2.sh

export HIVESERVER2_HADOOP_OPTS="-Xms2048m -Xmx2048m"
```



## 日志配置与优化

​		创建日志目录：

```shell
mkdir -p /data/hive-3.1.2/log
```

​		修改服务运行日志到指定目录：

```shell
> cp $HIVE_HOME/conf/hive-log4j2.properties.template $HIVE_HOME/conf/hive-log4j2.properties
> vim $HIVE_HOME/conf/hive-log4j2.properties

# property.hive.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}
property.hive.log.dir = /data/hive-3.1.2/log
```

​		调整日志打印级别，这一步调整主要在于登录hive管理员终端执行sql指令避免打印太多日志：

```shell
> vim $HIVE_HOME/conf/log4j.properties

log4j.rootLogger=WARN, CA
log4j.appender.CA=org.apache.log4j.ConsoleAppender
log4j.appender.CA.layout=org.apache.log4j.PatternLayout
log4j.appender.CA.layout.ConversionPattern=%-4r [%t] %-5p %c %x - %m%n
```



## 扩展脚本编写

### metastore启停维护

​		在$HIVE_HOME/bin目录下创建metastore-daemon.sh脚本用于管理metastore服务状态。

```shell
#!/bin/bash

HIVE_LOG_DIR=/data/hive-3.1.2/log
 
if [ ! -d $HIVE_LOG_DIR ]
then
  mkdir -p $HIVE_LOG_DIR
fi
 
function check_process()
{
  pid=$(ps -ef 2>/dev/null | grep -i "org.apache.hadoop.hive.metastore.HiveMetaStore" | grep -v grep | awk '{print $2}')
  echo $pid
  [ "$pid" ] && return 0 || return 1
}
 
function metastore_start()
{
  metapid=$(check_process)
  if [ -n "$metapid" ]; then
    echo "HiveMetaStore[pid: $metapid] has already exists!"
    return
  fi

  cmd="nohup $HIVE_HOME/bin/hive --service metastore >$HIVE_LOG_DIR/metastore.log 2>&1 &"
  eval $cmd

  if [ $? -eq 0 ]; then
    echo "HiveMetaStore has been running!"
  else
    echo "HiveMetaStore has been failed!"
  fi
}
 
function metastore_stop()
{
  metapid=$(check_process)
  [ "$metapid" ] && kill $metapid || echo "HiveMetaStore has been not running!"
}
 
case $1 in
 
"start")
  metastore_start
  ;;
 
"stop")
  metastore_stop
  ;;
 
"restart")
  metastore_stop
  sleep 2
  metastore_start
  ;;
 
"status")
  check_process >/dev/null && echo "Hive Metastore [Active]" || echo "Hive Metastore [Inactive]"
  ;;
 
*)
  echo Invalid Args!
  echo 'Usage: '$(basename $0)' start|stop|restart|status'
  ;;
 
esac
```

### metastore启停脚本

​		在$HIVE_HOME/conf/.metastore_node中配置文件配置该服务所部署的机器列表。

```shell
hcdb-nn1
hcdb-nn2
```

​		编写$HIVE_HOME/bin/metastoreX.sh用来控制所有节点的metastore服务启停。

```shell
#!/bin/bash

for node in `cat $HIVE_HOME/conf/.metastore_node`
do
  echo "********************************" [ $node ] "************************************"
  ssh $node $HIVE_HOME/bin/metastore-daemon.sh $1
  echo "*******************************************************************************"
done
```

### hiveserver2启停维护

​		在$HIVE_HOME/bin目录下创建hiveserver2-daemon.sh脚本用于管理hiveserver2服务状态。

```shell
#!/bin/bash

HIVE_LOG_DIR=/data/hive-3.1.2/log

if [ ! -d $HIVE_LOG_DIR ]
then
  mkdir -p $HIVE_LOG_DIR
fi

function check_process()
{
  pid=$(ps -ef 2>/dev/null | grep -i "org.apache.hive.service.server.HiveServer2" | grep -v grep | awk '{print $2}')
  echo $pid
  [ "$pid" ] && return 0 || return 1
}

function hiveserver_start()
{
  metapid=$(check_process)
  if [ -n "$metapid" ]; then
    echo "HiveServer2[pid: $metapid] has already exists!"
    return
  fi

  cmd="nohup $HIVE_HOME/bin/hive --service hiveserver2 >$HIVE_LOG_DIR/hiveserver2.log 2>&1 &"
  eval $cmd

  if [ $? -eq 0 ]; then
    echo "HiveServer2 has been running!"
  else
    echo "HiveServer2 has been failed!"
  fi
}

function hiveserver_stop()
{
  metapid=$(check_process)
  [ "$metapid" ] && kill $metapid || echo "HiveServer2 has been not running!"
}

case $1 in

"start")
  hiveserver_start
  ;;

"stop")
  hiveserver_stop
  ;;

"restart")
  hiveserver_stop
  sleep 2
  hiveserver_start
  ;;

"status")
  check_process >/dev/null && echo "HiveServer2 [Active]" || echo "HiveServer2 [Inactive]"
  ;;

*)
  echo Invalid Args!
  echo 'Usage: '$(basename $0)' start|stop|restart|status'
  ;;

esac
```

### hiveserver2启停脚本

​		在$HIVE_HOME/conf/.hiveserver2_node中配置文件配置该服务所部署的机器列表。

```shell
hcdb-nn2
```

​		编写$HIVE_HOME/bin/hiveserver2X.sh用来控制所有节点的hiveserver2服务启停。

```shell
#!/bin/bash

for node in `cat $HIVE_HOME/conf/.hiveserver2_node`
do
  echo "********************************" [ $node ] "************************************"
  ssh $node $HIVE_HOME/bin/hiveserver2-daemon.sh $1
  echo "*******************************************************************************"
done
```

### beeline命令行脚本

​		在$HIVE_HOME/bin/下创建beeline-cli

```shell
$HIVE_HOME/bin/beeline -u "jdbc:hive2://172.16.3.122:10000/default" \
-n hive \
-p hive \
--color=true \
--verbose=true \
--showDbInPrompt=true \
--incremental=true
```



## 启动服务

```shell
$HIVE_HOME/bin/metastoreX.sh start
$HIVE_HOME/bin/hiveserver2X.sh start
```



## FAQ

（1）初始化元数据库异常。

​		堆栈异常如下：

```shell
> schematool -initSchema -dbType postgres -verbose

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-3.2.4/share/hadoop/common/lib/slf4j-reload4j-1.7.35.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Reload4jLoggerFactory]
2023-01-10 11:39:53,993 INFO  [main] conf.HiveConf (HiveConf.java:findConfigFile(187)) - Found configuration file file:/opt/apache-hive-3.1.2-bin/conf/hive-site.xml
Exception in thread "main" java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338)
        at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:536)
        at org.apache.hadoop.mapred.JobConf.setJarByClass(JobConf.java:554)
        at org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:448)
        at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:5141)
        at org.apache.hadoop.hive.conf.HiveConf.<init>(HiveConf.java:5104)
        at org.apache.hive.beeline.HiveSchemaTool.<init>(HiveSchemaTool.java:96)
        at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1473)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
```

​		这个问题主要是由于Hive3.x依赖的guava版本太低所导致，解决方式如下：

```shell
rm $HIVE_HOME/lib/guava-19.0.jar
cp $HADOOP_HOME/share/hadoop/hdfs/lib/guava-27.0-jre.jar $HIVE_HOME/lib/
```

（2）Hive 3.1.2 在beeline客户端模式下执行insert into指令导致结果异常。

【现场堆栈】

​		beenline终端

```shell
0: jdbc:hive2://172.16.3.122:10000/default (default)> insert into tb values('2'),("3"),("4");
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.StatsTask (state=08S01,code=1)
java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.StatsTask
        at org.apache.hive.jdbc.HiveStatement.waitForOperationToComplete(HiveStatement.java:401)
        at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:266)
        at org.apache.hive.beeline.Commands.executeInternal(Commands.java:1005)
        at org.apache.hive.beeline.Commands.execute(Commands.java:1201)
        at org.apache.hive.beeline.Commands.sql(Commands.java:1130)
        at org.apache.hive.beeline.BeeLine.dispatch(BeeLine.java:1425)
        at org.apache.hive.beeline.BeeLine.execute(BeeLine.java:1287)
        at org.apache.hive.beeline.BeeLine.begin(BeeLine.java:1071)
        at org.apache.hive.beeline.BeeLine.mainWithInputRedirection(BeeLine.java:538)
        at org.apache.hive.beeline.BeeLine.main(BeeLine.java:520)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
```

​		hiveserver2日志

```shell
Automatically selecting local only mode for query
3309183 [HiveServer2-Background-Pool: Thread-699] WARN  org.apache.hadoop.hive.ql.Driver  - Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = zhongtai_20230129160547_6c400756-9363-4acd-971a-a236ea399348
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
3309196 [Thread-535] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl  - JobTracker metrics system already initialized!
3309213 [Thread-535] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl  - JobTracker metrics system already initialized!
3309214 [Thread-535] WARN  org.apache.hadoop.mapreduce.JobResourceUploader  - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
Job running in-process (local Hadoop)
3309535 [pool-163-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl  - JobTracker metrics system already initialized!
2023-01-29 16:05:48,641 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local118807278_0022
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory hdfs://ns/user/hive/warehouse/tb/.hive-staging_hive_2023-01-29_16-05-47_077_900224256432959327-25/-ext-10000
Loading data to table default.tb
3317403 [Thread-552] WARN  org.apache.hadoop.hive.metastore.RetryingMetaStoreClient  - MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. setPartitionColumnStatistics
org.apache.thrift.transport.TTransportException
        at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
        at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
        at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
        at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
        at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_set_aggr_stats_for(ThriftHiveMetastore.java:4104)
        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.set_aggr_stats_for(ThriftHiveMetastore.java:4091)
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.setPartitionColumnStatistics(HiveMetaStoreClient.java:1927)
        at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.setPartitionColumnStatistics(SessionHiveMetaStoreClient.java:409)
        at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:212)
        at com.sun.proxy.$Proxy37.setPartitionColumnStatistics(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2773)
        at com.sun.proxy.$Proxy37.setPartitionColumnStatistics(Unknown Source)
        at org.apache.hadoop.hive.ql.metadata.Hive.setPartitionColumnStatistics(Hive.java:4420)
        at org.apache.hadoop.hive.ql.stats.ColStatsProcessor.persistColumnStats(ColStatsProcessor.java:179)
        at org.apache.hadoop.hive.ql.stats.ColStatsProcessor.process(ColStatsProcessor.java:83)
        at org.apache.hadoop.hive.ql.exec.StatsTask.execute(StatsTask.java:108)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:205)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.run(TaskRunner.java:76)
3318600 [Thread-552] ERROR org.apache.hadoop.hive.ql.exec.StatsTask  - Failed to run stats task
org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.thrift.transport.TTransportException
        at org.apache.hadoop.hive.ql.metadata.Hive.setPartitionColumnStatistics(Hive.java:4423)
        at org.apache.hadoop.hive.ql.stats.ColStatsProcessor.persistColumnStats(ColStatsProcessor.java:179)
        at org.apache.hadoop.hive.ql.stats.ColStatsProcessor.process(ColStatsProcessor.java:83)
        at org.apache.hadoop.hive.ql.exec.StatsTask.execute(StatsTask.java:108)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:205)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.run(TaskRunner.java:76)
Caused by: org.apache.thrift.transport.TTransportException
        at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
        at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
        at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
        at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
        at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_set_aggr_stats_for(ThriftHiveMetastore.java:4104)
        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.set_aggr_stats_for(ThriftHiveMetastore.java:4091)
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.setPartitionColumnStatistics(HiveMetaStoreClient.java:1927)
        at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.setPartitionColumnStatistics(SessionHiveMetaStoreClient.java:409)
        at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:212)
        at com.sun.proxy.$Proxy37.setPartitionColumnStatistics(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2773)
        at com.sun.proxy.$Proxy37.setPartitionColumnStatistics(Unknown Source)
        at org.apache.hadoop.hive.ql.metadata.Hive.setPartitionColumnStatistics(Hive.java:4420)
        ... 6 more
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.StatsTask
3319193 [HiveServer2-Background-Pool: Thread-699] ERROR org.apache.hadoop.hive.ql.Driver  - FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.StatsTask
MapReduce Jobs Launched:
Stage-Stage-1:  HDFS Read: 18794 HDFS Write: 18931 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
3319200 [HiveServer2-Background-Pool: Thread-699] ERROR org.apache.hive.service.cli.operation.Operation  - Error running hive query:
org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.StatsTask
        at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:335)
        at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:226)
        at org.apache.hive.service.cli.operation.SQLOperation.access$700(SQLOperation.java:87)
        at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:316)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
        at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:329)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
```

【关联影响】

​		beeline客户端最终的指令结果为失败！同时数据成功插入至数据表中。

​		

​		所以说堆栈中的关键点是“org.apache.hadoop.hive.ql.exec.StatsTask  - Failed to run stats task”  这里的statstask是一个hive中用于统计插入等操作的状态任务。此信息类似于计数器用于告知用户插入数据的相关信息，但不影响程序的正常执行。临时的解决方案是删除metastore服务对应的数据库中的PART_COL_STATS表，具体可以参考：[Hive Metastore Connection Failure then Retry](https://juejin.cn/post/7098157597085138981)。但是这种方式在生产上没有进行过可行性验证，同时引发metastore服务异常的风险较大。

​		另一种说法是设置参数hive.stats.autogather为false，默认情况下是true。在源码中给出的解释如下：

```shell
A flag to gather statistics (only basic) automatically during the INSERT OVERWRITE command.
```

​		官方说这是3.1.2的bug，具体issue可以参考（[HIVE-19316](https://issues.apache.org/jira/browse/HIVE-19316)），大致意思是创建表时，元数据表列的某个属性为Ture则不允许插入。在hive4.0版本被修复，通过升级hive版本来解决该问题个方面考虑的难度较大。

​		所以推荐将hive.stats.autogather设置为false来规避这个问题。但造成的影响是在插入后不能及时感知到hive表的指标信息，特别是rawDataSize属性。但是同时可以通过analyze执行按需获取相关属性。

（3）hiveserver启动触发tez异常。

​		堆栈如下：

```shell
9312 [main] WARN  org.apache.hadoop.hive.conf.HiveConf  - HiveConf of name hive.stats.fetch.partition.stats does not exist
Hive Session ID = b987efb0-8a57-47ba-b2a4-e82601751197
9768 [main] WARN  org.apache.hive.service.server.HiveServer2  - No policy provider found, skip creating PrivilegeSynchonizer
9925 [main] WARN  org.apache.hive.service.server.HiveServer2  - Error starting HiveServer2 on attempt 1, will retry in 60000ms
java.lang.NoClassDefFoundError: org/apache/tez/dag/api/TezConfiguration
        at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolSession$AbstractTriggerValidator.startTriggerValidator(TezSessionPoolSession.java:74)
        at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.initTriggers(TezSessionPoolManager.java:207)
        at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.startPool(TezSessionPoolManager.java:114)
        at org.apache.hive.service.server.HiveServer2.initAndStartTezSessionPoolManager(HiveServer2.java:839)
        at org.apache.hive.service.server.HiveServer2.startOrReconnectTezSessions(HiveServer2.java:822)
        at org.apache.hive.service.server.HiveServer2.start(HiveServer2.java:745)
        at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:1037)
        at org.apache.hive.service.server.HiveServer2.access$1600(HiveServer2.java:140)
        at org.apache.hive.service.server.HiveServer2$StartOptionExecutor.execute(HiveServer2.java:1305)
        at org.apache.hive.service.server.HiveServer2.main(HiveServer2.java:1149)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
Caused by: java.lang.ClassNotFoundException: org.apache.tez.dag.api.TezConfiguration
        at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        ... 16 more

```

​		该问题属于Hive3.1.2不完善的地方，因为没有集成tez计算引擎所致，但是不会导致failove，该服务后续是可以正常运行的，但是会有60000ms后会自动重试启动（一般重试后会启动成功）从而感觉有慢启动的现象。在Hive3.1.2的源码中有这样一段代码：

```java
this.activePassiveHA = hiveConf.getBoolVar(ConfVars.HIVE_SERVER2_ACTIVE_PASSIVE_HA_ENABLE);

...

if (hiveConf.getVar(ConfVars.HIVE_EXECUTION_ENGINE).equals("tez")) {
    if (!activePassiveHA) {
        LOG.info("HS2 interactive HA not enabled. Starting tez sessions..");
        try {
            startOrReconnectTezSessions();
        } catch (Exception e) {
            LOG.error("Error starting  Tez sessions: ", e);
            throw new ServiceException(e);
        }
    } else {
        LOG.info("HS2 interactive HA enabled. Tez sessions will be started/reconnected by the leader.");
    }
}

...
```

​		具体代码上下文可以参考：[HiveServer2](https://github.com/apache/hive/blob/branch-3.1/service/src/java/org/apache/hive/service/server/HiveServer2.java)。

​		所以可以在hive-site.xml配置文件中配置如下参数即可：

```xml
<!-- hiveserver2的高可用参数，开启此参数可以提高hiveserver2的启动速度 -->
<property>
    <name>hive.server2.active.passive.ha.enable</name>
    <value>true</value>
</property>
```

​		
